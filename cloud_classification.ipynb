{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cloud_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Owjwav1EyO1R",
        "colab_type": "code",
        "outputId": "0c1e22ca-7bc5-4fcb-e520-8241bc545532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/Project ML\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Project ML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oD-pAJd18t3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Load Training Data with Returning Features and Labels\"\"\"\n",
        "\n",
        "def load_data(size):\n",
        "  #load data\n",
        "\n",
        "  images_path = os.listdir('progress 1/dummy_data/')\n",
        "  \n",
        "  label_map = {'free':[1,0,0],'thin':[0,1,0],'thick': [0,0,1]}\n",
        "  feature = []\n",
        "  label = []\n",
        "\n",
        "  for file_name in images_path:\n",
        "    \n",
        "    # Read image file\n",
        "    temp = cv2.imread('progress 1/dummy_data/' + file_name)\n",
        "    \n",
        "    # Resize image\n",
        "    im_resize = cv2.resize(temp,(size,size))\n",
        "    feature.append(im_resize)\n",
        "    \n",
        "    # Append labels.\n",
        "    label.append(label_map[file_name.split('_')[0]])\n",
        "   \n",
        "  label = np.array(label).astype(float)\n",
        "  return np.array(feature) / 255.0, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heuOM4SL-F_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn():\n",
        "  model = Sequential()\n",
        "  #Layer 1\n",
        "  #Conv Layer 1\n",
        "  model.add(Conv2D(filters = 6, \n",
        "                   kernel_size = 5, \n",
        "                   strides = 1, \n",
        "                   activation = 'relu', \n",
        "                   input_shape = (128,128,3)))\n",
        "  #Pooling layer 1\n",
        "  model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  #Layer 2\n",
        "  #Conv Layer 2\n",
        "  model.add(Conv2D(filters = 16, \n",
        "                   kernel_size = 5,\n",
        "                   strides = 1,\n",
        "                   activation = 'relu',\n",
        "                   input_shape = (64,64,6)))\n",
        "  #Pooling Layer 2\n",
        "  model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  #Flatten\n",
        "  model.add(Flatten())\n",
        "  #Layer 3\n",
        "  #Fully connected layer 1\n",
        "  model.add(Dense(units = 120, activation = 'relu'))\n",
        "  #Layer 4\n",
        "  #Fully connected layer 2\n",
        "  model.add(Dense(units = 84, activation = 'relu'))\n",
        "  #Layer 5\n",
        "  #Output Layer\n",
        "  model.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-DhU6IMbCoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_function(input_shape, filter_num, kernel_size):\n",
        "  model = Sequential()\n",
        "  #Layer 1\n",
        "  #Conv Layer 1\n",
        "  model.add(Conv2D(filters = filter_num[0], \n",
        "                   kernel_size = kernel_size[0], \n",
        "                   strides = 1, \n",
        "                   activation = 'relu', \n",
        "                   input_shape = (input_shape,input_shape,3)))\n",
        "  #Pooling layer 1\n",
        "  model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  #Layer 2\n",
        "  #Conv Layer 2\n",
        "  model.add(Conv2D(filters = filter_num[1], \n",
        "                   kernel_size = kernel_size[0],\n",
        "                   strides = 1,\n",
        "                   activation = 'relu',\n",
        "                   input_shape = (input_shape/2,input_shape/2,6)))\n",
        "  #Pooling Layer 2\n",
        "  model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "  #Flatten\n",
        "  model.add(Flatten())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ7tACoGEcnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a TensorBoard instance with the path to the logs directory\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zA3yfQoEgXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath = \"checkpoint/model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcXOGoDfGCk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data, train_label = load_data(128)\n",
        "train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o0MPzjD3EjeR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = {}\n",
        "train_data, train_label = load_data(128)\n",
        "#train_data, train_label = load_data(64)\n",
        "\n",
        "model = cnn_model_fn() \n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(train_data ,train_label, batch_size = 64, epochs = 42, validation_data=(train_data,train_label))#, callbacks=[tensorboard, checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "75TiXG3xdSwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_data = {}\n",
        "train_data1, train_label = load_data(128)\n",
        "train_data2, train_label = load_data(64)\n",
        "\n",
        "cnn1 = cnn_model_function(128, [64, 256], [36, 2])\n",
        "cnn2 = cnn_model_function(64, [32, 128], [12, 3])\n",
        "\n",
        "concat_layer = Concatenate([cnn1, cnn2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhZSrfd5hDM2",
        "colab_type": "code",
        "outputId": "bffad5d1-3cf9-49ce-bcb2-ad6b77661366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bY_pRmWaEl_a",
        "colab_type": "code",
        "outputId": "d8f33aee-94b1-4def-d3c6-f83835a247ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#testing\n",
        "scores = model.evaluate(train_data, train_label, batch_size=1, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 16ms/sample - loss: 1.9485e-05 - acc: 1.0000\n",
            "\n",
            "Test result: 100.000 loss: 0.000\n",
            "[1.948466899648338e-05, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2AzbBtDuzP7P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}